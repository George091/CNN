# CNN

# Part 1

We started with a basic 1D cnn and RNN structure. We used an embedding layer, a conv1D layer, a maxpool1d layer, a simple RNN layer, a dropout layer, a dense layer, and sigmoid 1 node output layer. All our default activation functions were ReLu because those functions are efficient to use. We started with a kernel size of 3. On 4 epochs this gave an accuracy of 77.6%. Changing the kernel size to 5 gave an accuracy of 80%.  Changing the kernel size to 10 gave an accuracy of 76.7%. Changing the kernel size to 7 gave an accuracy of 85%. Changing kernel size to 8 gave an accuracy of 70%. Changing kernel size to 6 gave an accuracy of 75%. Re-running with a kernel size of 7 gave an accuracy of 84%.

Then I changed the pooling size from 2-3. This gave an accuracy of 93% on the training set, but 76% on the testing set. The model clearly overfit, so we decided to add regularization. I decided to add a dropout of .3 between the CNN and RNN layers, and re-ran the model. This model resulted in an accuracy of 78% on the training set, and 84% on the testing set. The problem here was that the model did not train for enough epochs - it was still gaining significant accuracy. I re-ran the model here for 10 epochs and got 80.5% on the testing set. Interestingly, epoch 9 and 10 had accuracy of .89 and .76 respectively. It is interesting what happened in the training process here. I went ahead and increase max pooling size to 4 and re-ran the model. This model received an accuracy of 84%. Upping the pooling size to 5 only achieved 83% accuracy, therefore we deciding to take the next step and upgrade to a LSTM layer. We also changed the pooling size back to 4. This model achieved 75% accuracy on testing set and 83% on training set. We removed the LSTM layer and increased the # of filters to 32 and ran the model. Increasing filter to 32 gave us 87% accuracy on testing set (results are pickled in "CNN-RNN-1")

We then added back the bidirectional LSTM layer with 64 nodes and ran the model. We got a training set accuracy of 99% and testing set accuracy of 86.5%. There's clearly need for further regularization. I added dropout between embedding layer and the cnn layer. Added a shit ton of regularization and accuracy stayed at 50%. Reduced regularization and got 88% on testing set with 90% on training data. We ran another model after increasing filters in CNN and received 88.6% accuracy. We wondered if our dense layer was limiting the classification, so we increased the nodes of our dense layer.

We also experimented with the batch size, thinking that a smaller batch size would yield a more fine-tuned adjustment of the weights in the model, and therefore capture results with a higher accuracy. We found that decreasing the batch size from 64 to 32 in model.fit consistently provided a 1-2% increase in testing set accuracy.

We decided that our CNN should also be performing further feature extraction and dimensionality reduction, so we added an identical convolution and maxpooling layer following the first 1d CNN. We believed that this further step added adequate preprocessing of the movie review for the Bidirectional LSTM to capture short and long range dependencies to make an accurate prediction.

Another aspect of the CNN architecture we experimented with was padding. Interestingly enough, we found that same padding performed much better than valid padding in the convoluted layers. We believe that this is because valid padding does not allow the convolution layer's filter to capture enough information at the end and beginning of the movie review. By changing the padding to same, the filter was able to move over the items at the beginning and end of the review the same amkunt of times it moves over the items in the middle of the review, and thus catpures this periphery information. 

Dropout: we added dropout between each max pool and convolution layer, and after the LSTM. We also removed the dense layer after the LSTM, so that the LSTM directly fed into the output prediction node. We applied a standard sigmoid activation function to the output layer because our model is tasked with making a prediction of a binary classification.

We used binary cross entropy because we want our model to greatly penalize predictions that are confident and incorrect. We also used adam optimizer, but edited it so that we could directly change the learning rate. We found that using a learning rate of .000____ allowed us to get 89.94% accuracy on our test set. Finally, our metric was accuracy, as we wanted our model to just be able to get the most number of predictions correct out of the testing set.

# Part 2

We started with a base vanilla CNN model with a conv2d layer followed by a maxpooling layer, repeated 3 times.

We ran the model for 50 epochs and got 86% accuracy on the training set and 75.6% accuracy on the test set (results are pickled in "CNN-CIFAR"). Since the barrier seemed to be regularization, we decided to then increase regularization (increased drop out rate from .2 to .4 in dropout layers occurring after the conv2D and maxpooling layers) to try to get the remaining 4% accuracy. We also increased epochs to 100 to compensate for the increase in required training due to the increase in regularization. We ran the model for 100 epochs and got 77.18% accuracy on the training set and 75.97% accuracy on the test set (results are pickled in "CNN-CIFAR-1-ANDRE"). We noticed that there was not much increase in accuracy after 50 epochs for this model for the training set. Therefore, we decided to run a model with .3 drop out at 20 epochs. We had the understanding that .4 dropout may be unnecessary, and 100 epochs may be too large. When we changed parameters to .3 dropout at 20 epochs we got 81.9% accuracy on the training set and 78.6% accuracy on the test set (results are pickled in "CNN-CIFAR-1-GEORGE"). We decided to change the dropout rate to .2 after our CNN layers and .3 in the dense layer. This model resulted in an accuracy of 87.42% on the training data and 79.85% in testing data (results are pickled in "CNN-CIFAR-2-George"). We decided to up the epochs from 50 to 100 and we received an accuracy of 89.93% on the training data and 80.93% in testing data (results are pickled in "CNN-CIFAR-3-George"). We tried increasing batch size from 64 to 128 and received an accuracy of 88.07% on the training set and 80.78% on the testing set (results are pickled in "CNN-CIFAR-2-ANDRE"). To see if we could break through even higher accuracy we tried implementing data augmentation into our model. We ran this model for 50 epochs and received a training set accuracy of 80.4%. We decided to ditch this model since it provided no significant benefit over our previous model.. but we did consider data augmentation. Future work could look into implementing data augmentation in different ways to see if additional accuracy could be obtained.
